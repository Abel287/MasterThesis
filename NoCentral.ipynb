{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlrd\n",
    "from xlrd import open_workbook\n",
    "from scipy.stats import pearsonr \n",
    "from scipy.stats import powerlaw\n",
    "from collections import Counter\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import linregress \n",
    "import powerlaw\n",
    "import networkx as nx\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import warnings\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pprint\n",
    "import operator\n",
    "import math\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file ='DataRotterdam.xlsx'\n",
    "linknetwork= pd.read_excel(excel_file, sheet_name='Links',index_col=0)\n",
    "nodenetwork= pd.read_excel(excel_file, sheet_name='NodeCode', index_col=0)\n",
    "coordinates= pd.read_excel(excel_file, sheet_name='Coordinates', index_col=0)\n",
    "demandnetwork= pd.read_excel(excel_file, sheet_name='Demand', index_col=0)\n",
    "lines=pd.read_excel(excel_file, sheet_name='Lines', index_col=0)\n",
    "link_count = linknetwork.shape[0]\n",
    "node_count = nodenetwork.shape[0]\n",
    "line_count=lines.shape[0]\n",
    "demand_count=demandnetwork.shape[0]\n",
    "coordinates = coordinates.shape[0]\n",
    "book = open_workbook('DataRotterdam.xlsx')\n",
    "link_data = book.sheet_by_name('Links') #read link file and correct sheet\n",
    "node_data = book.sheet_by_name('NodeCode') #read node file and correct sheet\n",
    "coor_data = book.sheet_by_name('Coordinates') #read coordinate file\n",
    "line_data = book.sheet_by_name('Lines')\n",
    "demand_data = book.sheet_by_name('Demand')\n",
    "NodeLabel={} #create dictionary to name nodes based on station label\n",
    "NodeLines={} #create dictionary to determine which lines serve which node\n",
    "NodeHACode={}\n",
    "for i in range(link_count):\n",
    "    if link_data.cell_value(i+1, 2) not in NodeLabel and link_data.cell_value(i+1, 2) != 8000:\n",
    "        for j in range(node_count):\n",
    "            if int(node_data.cell_value(j+1, 0)) == int(link_data.cell_value(i+1, 2)):\n",
    "                NodeLabel[int(link_data.cell_value(i+1, 2))]= node_data.cell_value(j+1, 1)\n",
    "                NodeHACode[int(link_data.cell_value(i+1, 2))]= node_data.cell_value(j+1, 3)  \n",
    "    if link_data.cell_value(i+1, 3) not in NodeLabel and link_data.cell_value(i+1, 3) != 8000:\n",
    "        for j in range(node_count):\n",
    "            if int(node_data.cell_value(j+1, 0)) == int(link_data.cell_value(i+1, 3)):\n",
    "                NodeLabel[int(link_data.cell_value(i+1, 3))]= node_data.cell_value(j+1, 1)\n",
    "                NodeHACode[int(link_data.cell_value(i+1, 3))]= node_data.cell_value(j+1, 3) \n",
    "for i in NodeLabel:\n",
    "    NodeLines[i]=[]\n",
    "    for j in range(link_count):\n",
    "        if link_data.cell_value(j+1,2) == i and link_data.cell_value(j+1, 2) != 8000:\n",
    "            if link_data.cell_value(j+1,5) not in NodeLines[i]:\n",
    "                if link_data.cell_value(j+1,5) not in ['A', 'B', 'C', 'D', 'E']:\n",
    "                    NodeLines[i].append(int(link_data.cell_value(j+1,5)))\n",
    "                else:\n",
    "                    NodeLines[i].append(str(link_data.cell_value(j+1,5)))\n",
    "        if link_data.cell_value(j+1,3) == i and link_data.cell_value(j+1, 3) != 8000:\n",
    "            if link_data.cell_value(j+1,5) not in NodeLines[i]:\n",
    "                if link_data.cell_value(j+1,5) not in ['A', 'B', 'C', 'D', 'E']:\n",
    "                    NodeLines[i].append(int(link_data.cell_value(j+1,5)))\n",
    "                else:\n",
    "                    NodeLines[i].append(str(link_data.cell_value(j+1,5)))\n",
    "\n",
    "#Compute the number of internal nodes and links where external nodes van a label value of > 9900\n",
    "Internal_nodes=0\n",
    "for i in NodeLabel:\n",
    "    if i < 9900:\n",
    "        Internal_nodes += 1\n",
    "IntLinks=0\n",
    "for i in range(link_count):\n",
    "    if link_data.cell_value(i+1, 2) < 9900 or link_data.cell_value(i+1, 3) < 9900:\n",
    "        IntLinks += 1\n",
    "        \n",
    "#Import demand data and create OD matrix\n",
    "DemandData={}\n",
    "for i in range(1, demand_count+1):\n",
    "    for j in range(1, demand_count+1):\n",
    "        #if (int(demand_data.cell_value(i,0) >= 9900 and int(demand_data.cell_value(0,j)) >= 9900)):\n",
    "            #DemandData[int(demand_data.cell_value(i,0)),int(demand_data.cell_value(0,j))] = 0  \n",
    "        #else:\n",
    "        DemandData[int(demand_data.cell_value(i,0)),int(demand_data.cell_value(0,j))]= demand_data.cell_value(i,j)\n",
    "\n",
    "#read the characteristics of each Line        \n",
    "LineData={} \n",
    "for i in range(line_count):\n",
    "    if line_data.cell_value(i+1,0) not in ['A', 'B', 'C', 'D', 'E']:\n",
    "        LineData[int(line_data.cell_value(i+1,0))]={}\n",
    "    else:\n",
    "        LineData[str(line_data.cell_value(i+1,0))]={}\n",
    "    LineData[line_data.cell_value(i+1,0)][\"Modality\"]= line_data.cell_value(i+1,1)\n",
    "    LineData[line_data.cell_value(i+1,0)][\"Speed\"]= line_data.cell_value(i+1,2)\n",
    "    LineData[line_data.cell_value(i+1,0)][\"Frequency\"]= line_data.cell_value(i+1,3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine the location of each node and validate each node is given a location\n",
    "NodeLat={}\n",
    "NodeLeng={}\n",
    "NodeValidation={}\n",
    "for i in NodeHACode:\n",
    "    for j in range(1,coordinates+1):\n",
    "        if NodeHACode[i] == coor_data.cell_value(j,1):\n",
    "            NodeLat[i]= coor_data.cell_value(j,3)\n",
    "            NodeLeng[i]= coor_data.cell_value(j,4)\n",
    "            NodeValidation[i]= \"Yes\"\n",
    "    #some stops are not in the coordinate data set due to temporal rerouting, these are checked manually\n",
    "    if i not in (NodeValidation):\n",
    "        NodeLat[i]=0 \n",
    "        NodeLeng[i]=0\n",
    "        NodeValidation[i]= \"No\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Determine the distance between nodes which can be used to check if nodes are to closed and also to determine the link distance\n",
    "R = 6373.0 # approximate radius of earth in km\n",
    "InList=[]\n",
    "Dist={}\n",
    "for i in NodeLabel:\n",
    "    Dist[i]={}\n",
    "    for j in NodeLabel:\n",
    "        if i != j:\n",
    "            Dist[i][j]=0\n",
    "            if NodeLat[i] != 0:\n",
    "                lat1 = radians(float(NodeLat[i]))\n",
    "                lon1 = radians(float(NodeLeng[i]))\n",
    "                lat2 = radians(float(NodeLat[j]))\n",
    "                lon2 = radians(float(NodeLeng[j]))\n",
    "\n",
    "                dlon = lon2 - lon1\n",
    "                dlat = lat2 - lat1\n",
    "\n",
    "                a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "                c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "                Dist[i][j]= R * c * 1000\n",
    "                distance = R * c * 1000 #calculate distance in meters between every node\n",
    "#                 if distance < 150: # if the distance is smaller than 150 metres for two nodes, print the nodes\n",
    "#                     if NodeLabel[i] != NodeLabel[j]:\n",
    "#                         if ([NodeLabel[i], NodeLabel[j]]) not in InList:\n",
    "#                             print (NodeLabel[i], '\\&' , NodeLabel[j],  Dist[i][j])\n",
    "#                             InList.append([NodeLabel[i], NodeLabel[j]])\n",
    "#                             InList.append([NodeLabel[j], NodeLabel[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Prevent links going to the same node in case of a terminal station with the same label\n",
    "# for i in range(link_count):\n",
    "#     if NodeLabel[int(link_data.cell_value(i+1, 2))] == NodeLabel[int(link_data.cell_value(i+1, 3))]:\n",
    "#         print(int(link_data.cell_value(i+1, 2)), NodeLabel[int(link_data.cell_value(i+1, 2))],  int(link_data.cell_value(i+1, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If there are duplicates in the NodeLabels, this code can filter them\n",
    "# Duplicates=[]\n",
    "# DuplicatesNo={}\n",
    "# for k in (NodeLabel):\n",
    "#     for l in (NodeLabel):\n",
    "#         if k != l:\n",
    "#             if NodeLabel[k] == NodeLabel[l]:\n",
    "#                 if NodeLabel[k] not in Duplicates:\n",
    "#                     Duplicates.append(NodeLabel[k])\n",
    "# for i in Duplicates:\n",
    "#     DuplicatesNo[i]=[]\n",
    "#     for j in NodeLabel:\n",
    "#         if NodeLabel[j] == i:\n",
    "#             DuplicatesNo[i].append(j)\n",
    "# # for i in DuplicatesNo:\n",
    "# #     for j in DuplicatesNo[i]:\n",
    "# #         for k in DuplicatesNo[i]:\n",
    "# #              if j != k:\n",
    "# #                 if Dist[j][k] > 200:\n",
    "# #                     print(i, j, NodeLines[j])\n",
    "# #                     print(i, k, NodeLines[k])\n",
    "# DuplicatesNo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(link_count):\n",
    "#         if Dist[link_data.cell_value(i+1,2)][link_data.cell_value(i+1,3)] > 3000:\n",
    "#             if link_data.cell_value(i+1,2) < 9900 and link_data.cell_value(i+1,3) < 9900:\n",
    "#                 print(round(Dist[link_data.cell_value(i+1,2)][link_data.cell_value(i+1,3)],1), \n",
    "#                   NodeLabel[link_data.cell_value(i+1,2)], NodeLabel[link_data.cell_value(i+1,3)], link_data.cell_value(i+1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "638"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LineIndex=[] #give PT line index number \n",
    "LineStops=[] #number of stops per line\n",
    "for i in range(link_count): #loop over all nodes\n",
    "    if link_data.cell_value(i+1, 5) not in LineIndex: #if a line number is not added yet\n",
    "        if link_data.cell_value(i+1,5) not in ['A', 'B', 'C', 'D', 'E']:\n",
    "            LineIndex.append(int(link_data.cell_value(i+1, 5))) #add line index\n",
    "        else:\n",
    "            LineIndex.append(link_data.cell_value(i+1, 5)) #add line index\n",
    "        LineStops.append(1) #set number of stops to 1 initially\n",
    "for i in range(len(LineIndex)): #loop over all links\n",
    "    index=LineIndex[i] #set index to recall the line\n",
    "    x=[] #create variable x to define the highest stopnumber for a line\n",
    "    for j in range(link_count+1):\n",
    "        if link_data.cell_value(j, 5) == index: #if a node is served by a line\n",
    "            x = link_data.cell_value(j, 1) #set x to value of stopnumber\n",
    "            if x > int(LineStops[i]): #if x is higher than current highest stop number\n",
    "                LineStops[i]=int(x) #LineStops becomes x                                \n",
    "NumberOfLinks={}\n",
    "for i in range(len(LineIndex)):\n",
    "    j=LineIndex[i]\n",
    "    k=LineStops[i]\n",
    "    NumberOfLinks[j] =  k\n",
    "LineOverview={} \n",
    "StopsPerLine={}\n",
    "for j in LineIndex:\n",
    "    StopsPerLine[j]=[]\n",
    "    LineOverview[j]=[]\n",
    "    for i in range(link_count+1):\n",
    "        if link_data.cell_value(i, 5) == j:\n",
    "            for k in range(1,(NumberOfLinks[j]+1)):\n",
    "                if link_data.cell_value(i,1) == k: \n",
    "                    if k == 1:\n",
    "                        if link_data.cell_value(i, 2) != 8000:\n",
    "                            StopsPerLine[j].append(NodeLabel[int(link_data.cell_value(i, 2))])\n",
    "                            LineOverview[j].append(int(link_data.cell_value(i, 2)))\n",
    "                    if link_data.cell_value(i, 3) != 8000:\n",
    "                        StopsPerLine[j].append(NodeLabel[int(link_data.cell_value(i, 3))])\n",
    "                        LineOverview[j].append(int(link_data.cell_value(i, 3)))\n",
    "G=nx.empty_graph(NodeLabel,create_using=nx.Graph())\n",
    "#G=nx.empty_graph(NodeNo,create_using=nx.Graph()) #create graph\n",
    "for i in LineIndex: #Loop over number of Lines\n",
    "    for j in range(len(LineOverview[i])):\n",
    "        if j != len(LineOverview[i])-1:\n",
    "            k=j+1\n",
    "            x=LineOverview[i][j]\n",
    "            y=LineOverview[i][k]\n",
    "            G.add_edge(x,y) #Add a link between nodes k & l as it serves link j-1 - j for line index                        \n",
    "#nx.draw_networkx(G, with_labels=True) #draw the graph\n",
    "#nx.write_gexf(G, \"Amsterdam.gexf\") #export the graph to gephi file\n",
    "A = nx.adjacency_matrix(G)\n",
    "A.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_lines={}\n",
    "P_Graph = nx.Graph() #Create the P_Graph for element A and B\n",
    "G=nx.Graph() #Create graph in the L-space for element C and network visualization \n",
    "for i in NodeLabel:\n",
    "    G.add_node(i)\n",
    "    if i < 9900: #only add internal nodes \n",
    "        P_Graph.add_node(i)\n",
    "for i in LineIndex: #Loop over number of Lines\n",
    "    for j,k in zip(range(len(LineOverview[i])-1), range(1,len(LineOverview[i]))):\n",
    "            x=LineOverview[i][j]\n",
    "            y=LineOverview[i][k]\n",
    "            link_weight = Dist[x][y] / LineData[i][\"Speed\"]*3.6\n",
    "            for add in range(1,link_count+1):\n",
    "                if (link_data.cell_value(add, 5)) == i:\n",
    "                       if (link_data.cell_value(add, 2)) == x:\n",
    "                              if (link_data.cell_value(add, 3)) == y:\n",
    "                                    if link_data.cell_value(add, 6) != '':\n",
    "                                        link_weight += link_data.cell_value(add, 6)*60 #add stop time\n",
    "                                        if link_data.cell_value(add, 7) != '':\n",
    "                                                link_weight += link_data.cell_value(add, 7)*300 #add transfer time                \n",
    "            G.add_edge(x,y, weight = link_weight) #Add a link between nodes k & l as it serves link j-1 - j for line index\n",
    "    for j in LineOverview[i]:\n",
    "        for k in LineOverview[i]:\n",
    "            if j != k:\n",
    "                if (j < 9900 and k < 9900): #Only add internal links as external nodes are excluded\n",
    "                    P_Graph.add_edge(j,k)\n",
    "\n",
    "#Determine clustering coefficient for Element B\n",
    "Clustering = nx.clustering(P_Graph)\n",
    "\n",
    "#Determine eigenvector centrality for Element A\n",
    "EV = nx.eigenvector_centrality(P_Graph, max_iter=100)\n",
    "Max_EV = sorted(EV.items(), key=operator.itemgetter(1), reverse=True)\n",
    "EV_Weight = {}\n",
    "for i in EV:\n",
    "    EV_Weight[i] = EV[i] / (Max_EV[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create GG graph for shortest paths where each node is a combination of a node and line\n",
    "GG=nx.DiGraph()\n",
    "GG_Label={}\n",
    "GG_Node={}\n",
    "for i in NodeLabel:\n",
    "    GG_Node= 'origin',i\n",
    "    GG.add_node(GG_Node)\n",
    "    GG_Node= 'destination',i\n",
    "    GG.add_node(GG_Node)\n",
    "for i in LineIndex:\n",
    "    GG_Label[i]=[]\n",
    "    for j in LineOverview[i]:\n",
    "        GG_Label[i].append(j)\n",
    "    for j in GG_Label[i]:\n",
    "        GG_Node = i,j\n",
    "        GG.add_node(GG_Node)\n",
    "\n",
    "GG_weight=0        \n",
    "for i in GG.nodes:\n",
    "    k=i[1]\n",
    "    for j in GG.nodes:\n",
    "        if k==j[1]:\n",
    "            if i[0] != j[0]:\n",
    "                if (i[0] != 'origin' and i[0] != 'destination'):\n",
    "                    for freq in range(1,line_count+1):\n",
    "                        if line_data.cell_value(freq,0) == j[0]:\n",
    "                            GG.add_edge(i,j, weight = 180 + 3600/int(line_data.cell_value(freq,3))/2)\n",
    "                elif i[0] == 'origin' and j[0] != 'destination':\n",
    "                     GG.add_edge(i,j, weight = 0) #give high value of wait to prevent going through origin and destination nodes\n",
    "                elif i[0] == 'destination' and j[0] != 'origin':\n",
    "                     GG.add_edge(j,i, weight = 0) #give high value of wait to prevent going through origin and destination nodes\n",
    "    if (i[0] != 'origin' and i[0] != 'destination'):\n",
    "        for l in G.edges(i[1]):\n",
    "            for m in GG.nodes:\n",
    "                if i[0] == m[0]:\n",
    "                    if m[1] == l[1]:\n",
    "                        GG_weight = G.get_edge_data(i[1], m[1])['weight'] + 60 #plus stopping time\n",
    "                        GG.add_edge(m,i, weight = GG_weight)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine where the common corridors are located to prevent possible transfers in corridors by removing transfer edges\n",
    "CommonCorridor={}\n",
    "CommonEdges={}\n",
    "for i in G.edges:\n",
    "    CommonEdges[i]=[]\n",
    "    for j in GG.edges:\n",
    "        if j[0][1] == i[0] and j[1][1] == i[1]:\n",
    "            if j[0][0] not in CommonEdges[i]:\n",
    "                CommonEdges[i].append(j[0][0])            \n",
    "        elif j[0][1] == i[1] and j[1][1] == i[0]:\n",
    "            if j[0][0] not in CommonEdges[i]:\n",
    "                CommonEdges[i].append(j[0][0])\n",
    "for i in CommonEdges:\n",
    "    if len(CommonEdges[i]) > 1:\n",
    "        CommonCorridor[i]=CommonEdges[i]\n",
    "CorridorNodes=[]\n",
    "for i in CommonCorridor:\n",
    "    for j in CommonCorridor:\n",
    "        if i != j:\n",
    "            if i[0] == j[0] or i[0] == j[1]:\n",
    "                if G.degree(i[0]) <= 2:\n",
    "                    if CommonCorridor[i] == CommonCorridor[j]:\n",
    "                        if i[0] not in CorridorNodes:\n",
    "                            CorridorNodes.append(i[0])    \n",
    "            elif i[1] == j[0] or i[1] == j[1]:\n",
    "                        if G.degree(i[1]) <= 2:\n",
    "                            if CommonCorridor[i] == CommonCorridor[j]:\n",
    "                                if i[1] not in CorridorNodes:\n",
    "                                    CorridorNodes.append(i[1])\n",
    "CorridorEdges=[]\n",
    "for i in GG.edges:\n",
    "    if i[0][0] != 'origin' and i[1][0] != 'destination':\n",
    "        if i[0][1] == i[1][1]:\n",
    "            if i[0][1] in CorridorNodes:\n",
    "                CorridorEdges.append(i)\n",
    "for i in CorridorEdges:\n",
    "    GG.remove_edge(i[0],i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code determines the shortest paths for each node pair with demand based on the weight of the edges\n",
    "SP_list=[]\n",
    "pair=[]\n",
    "for i in GG.nodes:\n",
    "    if i[0] == 'origin': #start with origin\n",
    "        for j in GG.nodes:\n",
    "            if i[1] != j[1]:\n",
    "                if j[0] == 'destination': #end with destination\n",
    "                    if int(DemandData[(i[1], j[1])]) != 0: #only calculcate the shortest path if there is demand for the nodepair\n",
    "                        pair=i,j                    \n",
    "                        SP_list.append(pair)\n",
    "SP={}\n",
    "for i in range(len(SP_list)):\n",
    "    SP[(SP_list[i][0][1], SP_list[i][1][1])]= nx.shortest_path(GG, source= SP_list[i][0], target=SP_list[i][1],weight='weight')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine the transfer share for each node as part of Element C\n",
    "Transfer={}\n",
    "for i in NodeLabel:\n",
    "    Transfer[i]=0\n",
    "for i in SP:\n",
    "    O=i[0]\n",
    "    D=i[1]\n",
    "    Demand= int(DemandData[(i[0], i[1])])\n",
    "    Path=SP[i][1:-1]\n",
    "    for j,k in zip(range(1,len(Path)-1),range(2,len(Path))):\n",
    "        if Path[j][0] != Path[k][0]:\n",
    "            Transfer[Path[j][1]] += Demand\n",
    "Transfers={}\n",
    "TransferShare={}\n",
    "TOT_Transfers=0\n",
    "for i in NodeLabel:\n",
    "    if i < 9900:\n",
    "        TOT_Transfers += Transfer[i]\n",
    "for i in Transfer:\n",
    "    if i < 9900: #only for internal nodes\n",
    "        TransferShare[i]=Transfer[i]/TOT_Transfers\n",
    "        if Transfer[i] > 0:\n",
    "            Transfers[i]=math.log10(Transfer[i]) #take the log of transfers\n",
    "        else:\n",
    "            Transfers[i]=0\n",
    "Max_Trans = max(Transfers.items() , key=operator.itemgetter(1))[1]\n",
    "for i in Transfers:\n",
    "    Transfers[i] /= Max_Trans\n",
    "sorted_Transfers = sorted(Transfers.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "node={} #Create dictionary for node information\n",
    "eA={}\n",
    "eB={}\n",
    "eC={}\n",
    "H={} #Create dict for sorting the hierarchical degree of nodes\n",
    "HD={}\n",
    "for i in (NodeLabel):\n",
    "    if i < 9900:\n",
    "        if G.degree[i] > 2: #only if degree is higher than 2 the hierarchical degree can be computed\n",
    "            eA[i]=EV_Weight[i]   #variable for eA\n",
    "            eB[i]=(1-Clustering[i]) #formula for eB\n",
    "            eC[i]=(Transfers[i]*((G.degree[i]-2)/G.degree[i])) #formula for eC\n",
    "        else: #if the degree is lower or equal than 2, no values can be computed and are set to 0\n",
    "            eA[i]=0\n",
    "            eB[i]=0\n",
    "            eC[i]=0\n",
    "        H[NodeLabel[i]]=eA[i]*eB[i]*eC[i] #calculate the hierarchical degree\n",
    "        HD[i]= eA[i]*eB[i]*eC[i]\n",
    "        if H[NodeLabel[i]] != 0: #for every node which has a hierarchical degree which is not 0\n",
    "            node[i]= {'Node ID': i,\n",
    "                      'degree' : G.degree[i],\n",
    "                      'eA' : eA[i],\n",
    "                      'eB' : eB[i],\n",
    "                      'eC' : eC[i],\n",
    "                      'Hierarchical degree' : H[NodeLabel[i]]}\n",
    "\n",
    "#Create sorted lists to determine the highest scoring nodes for each element\n",
    "sorted_H = sorted(HD.items(), key=operator.itemgetter(1), reverse=True)\n",
    "sorted_eA = sorted(eA.items(), key=operator.itemgetter(1), reverse=True)\n",
    "sorted_eB = sorted(eB.items(), key=operator.itemgetter(1), reverse=True)\n",
    "sorted_eC = sorted(eC.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 & Station Schiedam Centrum & 0.739 & 1 & Beurs & 1.0\n",
      "2 & Zuidplein & 0.714 & 2 & Station Blaak & 0.901\n",
      "3 & Station Blaak & 0.676 & 3 & Station Schiedam Centrum & 0.887\n",
      "4 & Beurs & 0.667 & 4 & Zuidplein & 0.844\n",
      "5 & Stadhuis/Weena & 0.585 & 5 & Stadhuis/Weena & 0.819\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    j= i+1\n",
    "    print(j,'&', NodeLabel[sorted_eC[i][0]],'&',round(sorted_eC[i][1],3), '&', j,'&', NodeLabel[sorted_Transfers[i][0]],'&',round(sorted_Transfers[i][1],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . Beurs & 0.503 & 1.0 & 0.755 & 0.667 \\\n",
      "2 . Stadhuis/Weena & 0.446 & 0.974 & 0.783 & 0.585 \\\n",
      "3 . Station Schiedam Centrum & 0.412 & 0.72 & 0.775 & 0.739 \\\n",
      "4 . Marconiplein & 0.317 & 0.943 & 0.745 & 0.451 \\\n",
      "5 . Station Blaak & 0.295 & 0.643 & 0.68 & 0.676 \\\n",
      "6 . Eendrachtsplein & 0.201 & 0.568 & 0.722 & 0.492 \\\n",
      "7 . Kruisplein & 0.188 & 0.911 & 0.727 & 0.283 \\\n",
      "8 . Zuidplein & 0.167 & 0.264 & 0.882 & 0.714 \\\n",
      "9 . Station Alexander & 0.138 & 0.345 & 0.752 & 0.532 \\\n",
      "10 . Schiedam Nieuwland & 0.129 & 0.588 & 0.572 & 0.382 \\\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    get = sorted_H[i][0]\n",
    "    j = i+1\n",
    "    print(j, '.', NodeLabel[get], '&', round(HD[get],3), '&', round(eA[get],3), '&', round(eB[get],3), '&', round(eC[get],3), '\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8005"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_H[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brielselaan 0.002\n",
      "Putsebocht 1.719\n",
      "Breeplein 3.409\n",
      "Kerstendijk 1.479\n",
      "Smeetslandsedijk 0.749\n",
      "Grote Hagen 0.071\n",
      "Station Lombardijen 5.912\n",
      "Bredenoord 0.709\n",
      "Appeldijk 0.574\n",
      "Herenoord 1.128\n",
      "Nieuwenoord 0.064\n",
      "P+R Beverwaard 0.425\n",
      "Ahoy'-complex 1.586\n",
      "Zuiderparkweg 0.574\n",
      "Akkeroord 2.02\n",
      "Croystraat 0.148\n",
      "Oude Watering 1.029\n",
      "Schinnenbaan 0.378\n",
      "Beverwaardseweg 0.306\n",
      "Korperweg 0.013\n",
      "Waalhaven Zuidzijde 0.578\n",
      "Kaatsbaan 0.107\n",
      "Rietdijk 0.005\n",
      "Motorstraat 0.013\n",
      "De Twee Heuvels 0.002\n",
      "Strevelsweg 0.003\n",
      "Hillevliet 1.472\n",
      "Arendsweg 0.791\n",
      "Verboomstraat 2.728\n",
      "Sportlaan(Rotterdam) 0.098\n",
      "Den Hamweg 0.134\n",
      "Ophemertstraat 0.061\n",
      "Zaltbommelstraat 0.686\n",
      "Eemhavenweg 0.356\n",
      "Neptunusstraat 0.29\n",
      "Rondoplein 0.174\n",
      "Asterlo 3.071\n",
      "Larenkamp 0.347\n",
      "Zuiderbegraafplaats 0.195\n",
      "Victor Hugoweg 4.513\n",
      "Van de Woestijnestraat 2.502\n",
      "Dumasstraat 11.077\n",
      "Amelandseplein 0.064\n",
      "Molenwei 4.194\n",
      "Gruttostraat 0.043\n",
      "Keizerswaard 0.068\n",
      "Klein Nieuwland 2.684\n",
      "Spoorweghaven 0.117\n",
      "RDM Campus 1.497\n",
      "Burgdorfferstraat 0.072\n",
      "Station Zuid 0.037\n",
      "Kreekhuizenlaan(S) 0.51\n",
      "Waalhaven Westzijde 0.76\n",
      "Willem Egmondstraat 0.008\n",
      "Anthony Fokkerweg 0.001\n",
      "Zinkerstraat 0.253\n",
      "Nassauhaven 0.052\n",
      "Kreekhuizenlaan(N) 0.597\n",
      "Persoonsdam(E) 0.28\n",
      "Damstraat 0.601\n",
      "Carnissesingel 0.019\n",
      "Maeterlinckweg 2.175\n",
      "Pascalweg 0.013\n",
      "Kwartslaan 0.49\n",
      "Reesteijn 0.527\n",
      "Biezenlaan 1.275\n",
      "Regenboog 0.142\n",
      "Kreekhuizenlaan(M) 1.646\n",
      "Homerusstraat 0.717\n",
      "Hordijk 1.758\n",
      "Mandenmakerij 1.557\n",
      "Vrijheidsakker 0.291\n",
      "Viaduct A15 1.75\n",
      "Mathenesserbrug 0.009\n",
      "Vierambachtsstraat 1.226\n",
      "1e Middellandstraat 1.038\n",
      "Tiendplein 0.156\n",
      "Willem Ruyslaan 8.978\n",
      "Avenue Concordia 3.644\n",
      "Woudestein 3.187\n",
      "Kruisplein 0.463\n",
      "P.C. Hooftplein 0.178\n",
      "Stadhuis/Weena 186.474\n",
      "Lijnbaan 4.787\n",
      "Mecklenburglaan 0.206\n",
      "Schiekade 0.367\n",
      "Lage Filterweg 1.483\n",
      "Heer Bokelweg 0.028\n",
      "Noordsingel 0.415\n",
      "Eudokiaplein 0.092\n",
      "Van den Hoonaardstraat 0.298\n",
      "Soetendaalseweg 0.502\n",
      "Station Noord 1.094\n",
      "Kootsekade 1.149\n",
      "Lommerrijk 0.075\n",
      "Bergse Plaslaan 0.308\n",
      "C.N.A. Looslaan 0.163\n",
      "Bergse Dorpsstraat(S) 0.012\n",
      "Liduinaplein 0.34\n",
      "De Montignyplein 0.114\n",
      "Leuvehaven 86.171\n",
      "Burg. Van Walsumweg 2.608\n",
      "Essenlaan 0.348\n",
      "Spanjaardstraat 0.196\n",
      "Schiemond 0.143\n",
      "Oostkousdijk 0.758\n",
      "Pieter de Hoochweg 0.117\n",
      "Euromast 0.123\n",
      "Kievitslaan 0.132\n",
      "Vasteland 0.108\n",
      "Zwaanshals 1.298\n",
      "Benthuizerstraat 1.641\n",
      "'s-Gravenwetering 0.106\n",
      "Oude Plantage 1.521\n",
      "Bachplein 2.459\n",
      "Keizerstraat 0.012\n",
      "Boeier 1.413\n",
      "Teldersweg 0.005\n",
      "Boezemstraat 0.232\n",
      "Walenburgerweg 1.071\n",
      "Hof van Spaland 1.396\n",
      "Prinses Beatrixlaan 0.945\n",
      "Westplein 0.02\n",
      "Schieweg 0.883\n",
      "Franciscus Gasthuis 1.057\n",
      "Larikslaan 0.01\n",
      "Peppelweg 0.05\n",
      "Wilgenplaslaan 0.034\n",
      "Meent 0.208\n",
      "Zeilmakersstraat 0.201\n",
      "Van Duylstraat 0.747\n",
      "Molenvliet 0.983\n",
      "Beukendaal 2.356\n",
      "Vuurplaat 3.85\n",
      "Lodewijk Pincoffsweg 0.149\n",
      "Randweg 3.081\n",
      "Beijerlandselaan 0.309\n",
      "Sandelingplein 0.001\n",
      "Groene Hilledijk 0.287\n",
      "Paasweide 2.632\n",
      "Langenhorst 0.203\n",
      "Vrijenburgerbos 0.011\n",
      "Vrijenburg 0.22\n",
      "Meerwede 0.866\n",
      "Middeldijkerplein 3.13\n",
      "Waterkant 0.208\n",
      "Varkenoordseviaduct 0.994\n",
      "Stadion Feyenoord 4.543\n",
      "Noorderhelling 1.793\n",
      "Dwarsdijk 3.02\n",
      "Adriaan Volkerlaan 2.585\n",
      "Prinsenplein 3.094\n",
      "Parijslaan 0.497\n",
      "Over de Dammen 0.014\n",
      "De Loper 0.301\n",
      "Holysingel 0.377\n",
      "'s-Gravelandseweg 0.012\n",
      "Nesserdijk 1.395\n",
      "Pompenburg 0.134\n",
      "Jacob van Campenweg 0.064\n",
      "Jacob van Campenplein 0.05\n",
      "De Gaarden 0.045\n",
      "Van Doornestraat 0.065\n",
      "Lichtenauerlaan 0.026\n",
      "Argonautenweg 0.331\n",
      "Plaswijckpark 0.021\n",
      "Prinses Irenebrug 0.011\n",
      "Molenhoek 0.006\n",
      "Jeroen Boschlaan 0.021\n",
      "Plevierlaan 0.019\n",
      "Bergse Dorpsstraat(N) 0.341\n",
      "Grindweg 0.118\n",
      "Mathenesserplein 0.16\n",
      "Beukelsweg 0.045\n",
      "Abtsweg 0.001\n",
      "Ruggeweg 0.001\n",
      "Rotterdam Airport 0.712\n",
      "Noorderlaan 0.07\n",
      "Burgemeester Bosstraat 0.077\n",
      "West-Sidelinge 0.165\n",
      "2e Hogenbanweg 0.285\n",
      "Hoornweg 0.253\n",
      "Kleinpolderplein 0.001\n",
      "De Vlinderhoven 0.075\n",
      "De Akkers 0.005\n",
      "Harreweg 1.393\n",
      "Oosterflank 15.443\n",
      "Kerkhoflaan 0.033\n",
      "Burgemeester Meineszplein 0.075\n",
      "Noorderbrug 2.618\n",
      "Vondelstraat 2.332\n",
      "Beukelsdijk 0.226\n",
      "Vliegveldweg 0.005\n",
      "s-Gravendijkwal(S) 0.001\n",
      "Crooswijksestraat 0.749\n",
      "Heksendans 0.175\n",
      "Sara Burgerhart Erf 0.031\n",
      "Posthoorn 0.02\n",
      "Nieuwe Crooswijkseweg 2.272\n",
      "Paradijsplein 0.535\n",
      "Dillenburgsingel 0.403\n",
      "Begraafplaats Holy 0.048\n",
      "Laan van Bol'Es 0.037\n",
      "Erasmusplein 0.241\n",
      "Buys Ballotlaan 0.849\n",
      "Dirk de Derdelaan 0.493\n",
      "Philips de Goedestraat 0.593\n",
      "Blois van Treslongstraat 0.63\n",
      "Billitonlaan 0.936\n",
      "V.d. Duyn v. Maasdamln. 0.306\n",
      "Rotterdamseweg 0.774\n",
      "Meidoornstraat 2.388\n",
      "Anna Paulownalaan 0.763\n",
      "Lepelaarsingel 0.396\n",
      "Leersumhoeve 0.265\n",
      "Verploegh Chasséplein 1.007\n",
      "Stadsgehoorzaal 1.776\n",
      "Liesveldviaduct 2.798\n",
      "Sportlaan(Vlaardingen) 1.699\n",
      "Koninginnelaan 2.407\n",
      "Het Zonnehuis 0.895\n",
      "Wiardi Beckmansingel 0.129\n",
      "Holierhoek 0.441\n",
      "Gatwickbaan 0.125\n",
      "Burg. Van Kempensingel 0.343\n",
      "Alexandrium II 0.148\n",
      "Wilgendreef 0.041\n",
      "Overdrevenpad 0.084\n",
      "Platanendreef 0.089\n",
      "Zaagmolenbrug 1.186\n",
      "Winkelhoeve 0.167\n",
      "Port Saïdstraat 0.05\n",
      "G.H. Betzweg 0.481\n",
      "Ringvaartplas 0.632\n",
      "Klapwiek 0.261\n",
      "Huslystraat 0.098\n",
      "Alexandrium I 1.207\n",
      "Zeldenrust-Noordanuslaan 0.389\n",
      "Blijdorpplein 0.025\n",
      "Vroesenpark 0.027\n",
      "Van der Sasstraat 0.096\n",
      "Nico van der Valkweg 0.031\n",
      "Station Schollevaar 2.099\n",
      "Mr. L.A. Kesperweg 1.014\n",
      "Tochtbrug 0.044\n",
      "Station Barendrecht 2.004\n",
      "De Lugt 0.232\n",
      "Molen 0.003\n",
      "Doenpad 0.051\n",
      "HES 0.363\n",
      "Vaanweg 0.106\n",
      "Spinozaweg 6.025\n",
      "Raadhuisplein 0.864\n",
      "Koekoekstraat 0.854\n",
      "Middenwetering 0.235\n",
      "Nieuwe Vliet 0.22\n",
      "Van Ostadelaan 3.042\n",
      "Lansingh Zuid 0.505\n",
      "Fidelio 0.412\n",
      "Traviata 0.662\n",
      "Industrieweg 0.036\n",
      "Olympiade 0.347\n",
      "Moderato 0.196\n",
      "Fresia 0.831\n",
      "Narcis 0.101\n",
      "Els 0.391\n",
      "Zwanenkade 0.514\n",
      "Vijverlaan 0.331\n",
      "Gouden Regen 0.283\n",
      "Sprietzeil 0.06\n",
      "Van Utrechtweg 0.165\n",
      "Hollandia 0.392\n",
      "Waterbus Stormpolder 0.005\n",
      "Benedenrijweg 0.171\n",
      "Keizerswaard/Gr.v.Zoelenlaan 0.721\n",
      "Van Hoochstratenweg 0.161\n",
      "Koninginneweg 0.001\n",
      "Rijnsingel 0.24\n",
      "Lindehoevelaan 0.154\n",
      "Park Buitenoord 0.028\n",
      "J.G. Oemvliet 0.517\n",
      "Spinetstraat 0.409\n",
      "Cellolaan 0.24\n",
      "Muziekplein 0.864\n",
      "Hotel van der Valk 4.511\n",
      "Krimpen Busstation 0.902\n",
      "Boerhaavelaan 1.557\n",
      "Dorpsstraat 0.215\n",
      "Waalhaven Noordzijde 0.18\n",
      "Dokhaven 0.522\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "8000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-3846da68fe44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m8019\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mDemandData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNodeLabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDemandData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 8000"
     ]
    }
   ],
   "source": [
    "for i in DemandData:\n",
    "    if i[0] == 8019:\n",
    "        if DemandData[i] != 0:\n",
    "            print(NodeLabel[i[1]], DemandData[i])\n",
    "    elif i[1] == 8019:\n",
    "        if DemandData[i] != 0:\n",
    "            print(NodeLabel[i[0]], DemandData[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the results for the highest scoring nodes\n",
    "Results={}\n",
    "for i in range(0,20): #Reverse loop to begin at the end of the list\n",
    "    Results[(sorted_H[i][0])]=[NodeLabel[sorted_H[i][0]],round(sorted_H[i][1],3),round(eA[sorted_H[i][0]],3)\n",
    "                                , round(eB[sorted_H[i][0]],3), round(eC[sorted_H[i][0]],3)]\n",
    "    print(Results[(sorted_H[i][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Draw a map of the graph based on latitude and longtitude coordinates\n",
    "sorted_ID = sorted(HD.items(), key=operator.itemgetter(1)) #order nodes from low to high\n",
    "H = nx.Graph() #create graph for drawing\n",
    "colormap=[] #color of nodes based on H value\n",
    "size=[] #size of nodes based on H value\n",
    "for i in range(len(sorted_ID)): \n",
    "    if sorted_ID[i][0] < 9900: #only internal nodes\n",
    "        H.add_node(sorted_ID[i][0], pos=(float(NodeLeng[sorted_ID[i][0]]),float(NodeLat[sorted_ID[i][0]])))\n",
    "        colormap.append(math.log10(1+float(sorted_ID[i][1])))\n",
    "        size.append(10+1500*math.log10(1+float(sorted_ID[i][1])))    \n",
    "for i in G.edges:\n",
    "    if (i[0] < 9900 and i[1] < 9900): #only fully internal links\n",
    "        H.add_edge(i[0],i[1])\n",
    "# NodeRank={}\n",
    "# rank=0\n",
    "# for i in reversed(sorted_ID):\n",
    "#     rank += 1\n",
    "#     if rank < 10:\n",
    "#         NodeRank[i[0]] = rank\n",
    "#     else:\n",
    "#         NodeRank[i[0]]= \n",
    "        \n",
    "#Plot the figure        \n",
    "plt.figure(figsize=(18,12))\n",
    "# H=nx.relabel_nodes(H,NodeRank) # can be used to label the nodes\n",
    "plt.title('Hierarchy of nodes in the Rotterdam PTN ', fontsize = 18, weight='bold', verticalalignment='center')\n",
    "nx.draw(H, nx.get_node_attributes(H,'pos'), with_labels=False, line_edge=1, node_size=size, node_color = colormap,\n",
    "        vmin = 0, vmax=0.15, cmap='viridis', linewidths=1, edgecolors='black', legend=True)\n",
    "sm = plt.cm.ScalarMappable(cmap=plt.cm.get_cmap('viridis'), norm=plt.Normalize(vmin = 0, vmax=0.4))\n",
    "sm._A = []\n",
    "cbar = plt.colorbar(sm, orientation=\"horizontal\", fraction=0.033, pad=0) \n",
    "cbar.set_label(label='H$_\\mathbf{i}$ values', size=15, weight='bold')\n",
    "cbar.ax.xaxis.set_label_position('top')\n",
    "cbar.ax.xaxis.set_ticks_position('top')\n",
    "plt.savefig('NodeHierarchy010NoCentral.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# nx.write_gexf(H, \"Rotterdam.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for power-law distribution calculation\n",
    "#for dist_type in [HD, eA, eB, eC]:\n",
    "dist_type = HD\n",
    "c = {}\n",
    "values=np.arange(0,1,0.05)\n",
    "data=[]\n",
    "for j in values:\n",
    "    Counting = 0\n",
    "    for i in dist_type.values():\n",
    "        if i >= j:\n",
    "            Counting += 1\n",
    "            if j > 0:\n",
    "                data.append(j)\n",
    "        c[round(j,2)]=Counting / len(HD)\n",
    "x=[]\n",
    "y=[]\n",
    "for i in c:\n",
    "    if i > 0 and c[i] > 0:\n",
    "        x.append(np.log(i))\n",
    "        y.append(np.log(c[i]))\n",
    "slope, intercept, r_value, p_value, std_err = sp.stats.linregress(x, y)\n",
    "k=slope\n",
    "\n",
    "#Create the plot\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.style.use('bmh')\n",
    "ax = plt.axes(yscale='log')\n",
    "alpha_label = '\\u03B1 ~ {}' .format(str(round(k,3)))\n",
    "plt.ylim(0.001, 1.1)\n",
    "plt.xlim(-0.02,1.0)\n",
    "plt.title('Distribution function of H$\\mathdefault{^i}$')\n",
    "plt.xlabel('H$\\mathdefault{^i}$ values', fontsize=14)\n",
    "plt.ylabel('Fraction of nodes with a higher H$\\mathdefault{^i}$ value', fontsize=14)\n",
    "plt.scatter(*zip(*sorted(c.items())), marker='o', s=60, linewidths=1,  edgecolors='k',zorder=2)\n",
    "plt.text(0.42, 0.15, alpha_label, color='r', fontsize=14,\n",
    "        bbox={'facecolor': 'white', 'linestyle': 'solid',\n",
    "         'linewidth': 2, 'edgecolor': 'black', 'alpha': 0.2, 'pad': 6})\n",
    "\n",
    "\n",
    "rangedata = np.linspace(0.001, 1.0,100000)        \n",
    "plt.plot(rangedata,np.power(rangedata,k)/(1.7*len(HD)),'r',zorder=1);\n",
    "plt.savefig('PowerDistribution010.png')\n",
    "plt.show();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counting=0\n",
    "for i in NodeLabel:\n",
    "    if i < 9900:\n",
    "        if HD[i] != 0:\n",
    "            Counting += 1\n",
    "print(Counting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "for x,y,z in zip([eA, eB, eC, Transfers],['eA', 'eB', 'eC','Transfers'],\n",
    "                 ['e$\\mathdefault{^A}$', 'e$\\mathdefault{^B}$', 'e$\\mathdefault{^C}$', 'Normalized transfer share']):\n",
    "    data=[]\n",
    "    for i in x:\n",
    "        data.append(x[i])\n",
    "    data_sorted= list(sorted(data))\n",
    "    p = 1. * np.arange(len(data)) / (len(data) - 1)\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.style.use('bmh')\n",
    "    plt.plot(data_sorted, p)\n",
    "    plt.ylim(0.70,1.01) \n",
    "    plt.xlim(-0.02,1.01)\n",
    "    plt.ylabel('Cumulative distribution')\n",
    "    if z != 'Normalized transfer share':\n",
    "        plt.xlabel('{} values' .format(z))\n",
    "    else:\n",
    "        plt.xlabel('{}' .format(z))\n",
    "    if z != 'Normalized transfer share':\n",
    "        plt.title('Cumulative distribution function of {}'.format(z), fontsize=12 )\n",
    "    else:\n",
    "        plt.title('Cumulative distribution function of transfer share', fontsize=12 )\n",
    "    plt.savefig('CDF{}010.png' .format(y))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(list_of_values): #Algorithm to define the gini index\n",
    "    sorted_list = sorted(list_of_values)\n",
    "    height, area = 0, 0\n",
    "    for value in sorted_list:\n",
    "        height += value\n",
    "        area += height - value / 2.\n",
    "    fair_area = height * len(list_of_values) / 2.\n",
    "    return (fair_area - area) / fair_area\n",
    "\n",
    "Internal=[] #Add variable list for all nodes with a hierarchical degree of not zero\n",
    "for i in HD:\n",
    "    if i < 9900:\n",
    "        Internal.append(HD[i])\n",
    "Cummulative=0\n",
    "Entry=list(range(1,len(Internal)+1)) #ranking for sorted hierarchical degrees based on number of entries\n",
    "Ranking=sorted(Internal) #the ranking of the hierarchical degree list\n",
    "Height=[0]\n",
    "for i in Internal:\n",
    "    Cummulative += i\n",
    "for i in Ranking:\n",
    "    Height.append(Height[-1]+i)\n",
    "Height.pop(0) #remove first value which was added as initial\n",
    "gini = round(gini(Internal),3) #the gini index value with 2 decimals\n",
    "\n",
    "#Create the plot\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.style.use('bmh')\n",
    "x = Entry\n",
    "Equal=[]\n",
    "for i in Entry:\n",
    "    Equal.append(i/len(Entry)*Cummulative)\n",
    "y1 = Equal\n",
    "y2 = Height\n",
    "plt.plot([0,len(Internal)],[0,Cummulative])\n",
    "plt.plot(Entry,Height)\n",
    "plt.xlim(0,len(Internal))\n",
    "plt.ylim(0,Cummulative)\n",
    "plt.text(120, 4.5, 'Gini index = {}'.format(gini), color='b', fontsize=16,\n",
    "        bbox={'facecolor': 'white', 'linestyle': 'solid',\n",
    "         'linewidth': 2, 'edgecolor': 'black', 'alpha': 0.2, 'pad': 6})\n",
    "plt.tick_params(labelsize=12)\n",
    "plt.xticks(np.arange(0, len(Internal)+1,len(Internal)/5), ('0', '0.2', '0.4', '0.6', '0.8','1'))\n",
    "plt.grid(False)\n",
    "plt.text(520, 0.7, 'Lorenz curve', rotation=75, fontsize=14, weight='bold', zorder=2)\n",
    "plt.text(225, 2.2, 'Line of Equality', rotation=37, fontsize=14, weight='bold', zorder=2)\n",
    "plt.ylabel('Cummulative hierarchical degree of nodes', fontsize=12 )\n",
    "plt.xlabel('Fraction of nodes', fontsize=12)\n",
    "plt.fill_between(x, y1, y2, facecolor='red', interpolate=True, alpha=0.5, zorder=1)\n",
    "plt.fill_between(x, 0, y2, facecolor='green', interpolate=True, alpha=0.5)\n",
    "plt.title(\"Gini Index of the hierarchical degree \");\n",
    "plt.savefig('GiniDistribution010.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Verification of the transfer model\n",
    "# Verification=[]\n",
    "# VerificationSP=[]\n",
    "# for i in SP:\n",
    "#     VerificationSP.append(i) \n",
    "# import random\n",
    "# for i in range (0,10):\n",
    "#     j=random.randint(0,len(VerificationSP))\n",
    "#     Verification.append(VerificationSP[j])\n",
    "# for i in Verification:\n",
    "#     print(SP[i])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistical analysis of nodes\n",
    "Between= nx.betweenness_centrality(G) #use networkX tool to create dict with betweenness for each node\n",
    "Statistics={} #Dict to capture all statistics of a node\n",
    "As={} #Dict for assortativity\n",
    "Modes={} #Dict for the modes serving each node for overlapping degree\n",
    "OverDeg={} #Dict for degree in each layer for each node\n",
    "for i in HD:\n",
    "    if HD[i] != 0:\n",
    "        Statistics[i]={}\n",
    "        Statistics[i]['H']=HD[i]\n",
    "        Statistics[i]['k']=G.degree[i]\n",
    "        Statistics[i]['eA']=eA[i]\n",
    "        Statistics[i]['eB']=eB[i]\n",
    "        Statistics[i]['eC']=eC[i]\n",
    "        As[i]=0 \n",
    "        for j in G.edges(i):\n",
    "            As[i] += G.degree(j[1])\n",
    "        Statistics[i]['A']=As[i]/len(G.edges(i)) #Average degree of neighbors\n",
    "        Statistics[i]['C']=Clustering[i]\n",
    "        Modes[i]={} # add dict for each node to create a list for each mode\n",
    "        OverDeg[i]=[] #add list to determine degree for each mode\n",
    "        for j in NodeLines[i]:\n",
    "            if LineData[j]['Modality'] not in Modes[i]: #the mode did not exist yet for the node\n",
    "                Modes[i][LineData[j]['Modality']]=[j]\n",
    "            else:\n",
    "                Modes[i][LineData[j]['Modality']].append(j) #if the mode is already in the list\n",
    "        for j in Modes[i]:\n",
    "            for k in Modes[i][j]:\n",
    "                for l in range(len(LineOverview[k])): #find the location of the node on the line\n",
    "                    if LineOverview[k][l] == i:\n",
    "                        if l != 0:\n",
    "                            if [j, LineOverview[k][l-1]] not in OverDeg[i]: #add one node before node i to the list\n",
    "                                OverDeg[i].append([j, LineOverview[k][l-1]])\n",
    "                        if l != len(LineOverview[k])-1:\n",
    "                            if [j, LineOverview[k][l+1]] not in OverDeg[i]: #add one node fater node i to the list\n",
    "                                OverDeg[i].append([j, LineOverview[k][l+1]])\n",
    "        Statistics[i]['O']=len(OverDeg[i])\n",
    "        Statistics[i]['B']=Between[i]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(Stat['H'], Stat['A'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stat={}   \n",
    "for j in ['eA','eB','eC','H','k','A','C','O','B']:\n",
    "    Stat[j]=[]\n",
    "    for i in Statistics:    \n",
    "        Stat[j].append(Statistics[i][j])\n",
    "\n",
    "#Plot the pearson correlation between H and the elements in one figure\n",
    "\n",
    "fig, (axs) = plt.subplots(2, 3, figsize=(15,10))\n",
    "fig.suptitle('Correlation between elements and hierarchical degree', fontsize=18)\n",
    "plt.style.use('bmh')\n",
    "(ax1, ax2, ax3), (ax4, ax5, ax6) = axs\n",
    "for i,j, k, xlabels, ylabels in zip([ax1, ax2, ax3, ax4, ax5, ax6],['eA','eB','eC', 'eA','eA','eB'],['H','H','H', 'eB','eC','eC'],\n",
    "                                    ['e$\\mathdefault{^A}$','e$\\mathdefault{^B}$','e$\\mathdefault{^C}$', \n",
    "                                     'e$\\mathdefault{^A}$','e$\\mathdefault{^A}$','e$\\mathdefault{^B}$'],\n",
    "                                    ['H','H','H', 'e$\\mathdefault{^B}$','e$\\mathdefault{^C}$','e$\\mathdefault{^C}$']):\n",
    "    i.grid(b=None)\n",
    "    if k == 'H':\n",
    "        i.set_ylim([0, 0.8])\n",
    "        height=0.59\n",
    "    else:\n",
    "        i.set_ylim([0, 1.2])\n",
    "        height=0.88\n",
    "    corr, _ = pearsonr(Stat[j], Stat[k])\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(Stat[j], Stat[k])\n",
    "    x=np.linspace(0, 1.0,100000)\n",
    "    i.plot(x, intercept + slope*x, 'r-')\n",
    "    i.scatter(Stat[j], Stat[k], s=30, edgecolor='black', linewidth='0.75')\n",
    "    i.set(xlabel='{} values'.format(xlabels), ylabel='{} values'.format(ylabels))\n",
    "    SlopeLabel = str(round(slope,3)) \n",
    "    i.text(0.02, height, 'Pearson correlation: %s \\n\\nSlope regression line: %s \\n\\nStandard error: %s ' \n",
    "           % (round(corr,3), round(slope,2) , round(std_err,2)) , \n",
    "           color='k', fontsize=11, bbox={'facecolor': 'white', 'linestyle': 'solid', 'linewidth': 2, \n",
    "                                         'edgecolor': 'black', 'alpha': 0.8, 'pad': 6})   \n",
    "plt.savefig('Correlation.png')\n",
    "plt.plot;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total travel time in the network\n",
    "Tot_Dem=0\n",
    "Tot_TT=0\n",
    "for j in SP:\n",
    "    for i in range(len(SP[j])-1):\n",
    "        Tot_TT += (GG.get_edge_data((SP[j][i]),(SP[j][i+1]))['weight']) * DemandData[j]\n",
    "    Tot_Dem += DemandData[j]\n",
    "print('Total daily travel time =', int(Tot_TT/3600), 'hours')\n",
    "print('Total daily demand =', int(Tot_Dem), 'passengers')\n",
    "print('Average daily travel time =', int(Tot_TT/Tot_Dem/60), 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Create a new excel file to couple nodes from different datasets\n",
    "# import xlsxwriter\n",
    "\n",
    "# # Create a new Excel file and add a worksheet.\n",
    "# workbook = xlsxwriter.Workbook('Dataset.xlsx')\n",
    "# worksheet = workbook.add_worksheet()\n",
    "# worksheet.write(0,0,\"NodeID\")\n",
    "# worksheet.write(0,1,\"NodeLabel\")\n",
    "# j=1\n",
    "# for i in NodeLabel:\n",
    "#     worksheet.write(j, 0, i)\n",
    "#     worksheet.write(j, 1, NodeLabel[i])\n",
    "#     j += 1\n",
    "# workbook.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
